setwd("/Users/user/Documents/datavisualization_labs")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
## coin tossing example. 10 throws. Count n. heads, repeat 20 times.
## Assume normal distribution with mean 5 and SD mean/3.5
set.seed(123) # ensure random sampling will give same values every time with this seed.
minVal <- 0 # set min value
maxVal <- 10 # set max value
mn <- (maxVal - minVal)/2 # average
# Generate 20 numbers (mostly) from min to max
x <- rnorm(20, mean = mn, sd = mn/3.5)
# Change the out-of-bounds generated values to min o max value
x <- pmax(minVal, x)
x <- pmin(maxVal, x)
# round all values as coin tossing produces integers (number of heads out of 10 throws)
x <- round(x)
x
instance =c(1:10)
time = c(386.1, 386.1, 389.6, 406.1, 407.5, 424.0, 427.5, 429.5, 443.3, 457.8 )
swTimes <- data.frame(instance , time)
p <- ggplot(swTimes, aes(sample = time))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
shapiro.test(swTimes$time)
p <- ggplot(swTimes, aes(x= time))
p <- p+ geom_dotplot( binwidth=1 )
p <- p + labs( x="",y="")
p <- p + xlim(370,460)
p
# number of instances of data
n <- length(swTimes$time)
# Confidence and significance
confidence <- 0.95
significance <- 1- confidence
# two-tailed so half
halfSignificance <- significance/2
a <- 1 - halfSignificance
# degrees of freedom
dfTimes <- n - 1
# finding t-value
# function qt returns required value for t
t <- qt(a, dfTimes)
t
#standard deviation for times data
sdTimes <- sd(swTimes$time)
# margin of error
error <- t*sdTimes/sqrt(n)
error
# mean value
meanTimes <- mean(swTimes$time)
meanTimes
# Lower and upper limits
lowerlimit <- meanTimes - error
upperlimit <- meanTimes + error
# confidence interval
CI <- paste("Confidence interval is (", lowerlimit, ", ",  upperlimit, ")")
CI
t.test(swTimes$time, alternative = "two.sided", paired=F, mu= 400, conf.level=0.9)
engines <- read.csv("channel.csv", header = T, stringsAsFactors = T)
engines <- read.csv("channel.csv", header = T, stringsAsFactors = T)
engines <- read.csv("engineData.csv", header = T, stringsAsFactors = T)
engines <- read.csv("engineData.csv", header = T, stringsAsFactors = T)
p <- ggplot(engines, aes(sample = Difference))
p <- p + stat_qq()
p<- p + stat_qq_line( )
p
shapiro.test(engines$Difference)
t.test(x=engines$Search.engine.A, y=engines$Search.engine.B , alternative = "two.sided", paired=T, mu= 0, conf.level=0.95)
Job.1 <- c(17.2,18.3,17.4,19.6,19,14.6,18.6,16.5,15.4,20.2,18,16.5,21.7,19.4,NA)
Job.2 <- c(17.2,19.9,21.6,21.1,19.1,18.4,22.3,19.9,21.3,18.6,19.4,16.6,20.7,23.8,20.5)
jobs <- data.frame(Job.1, Job.2)
# jobs <- read.csv("jobs.csv", header=T, stringsAsFactors=T)
p <- ggplot(jobs, aes(sample = Job.1))
p <- p + stat_qq()
p <- p + stat_qq_line()
p <- p+  theme_classic()
p
p <- ggplot(jobs, aes(sample = Job.2))
p <- p + stat_qq()
p<- p+ stat_qq_line()
p
shapiro.test(jobs$Job.1)
shapiro.test(jobs$Job.2)
t.test(jobs$Job.1, y=jobs$Job.2 , alternative = "two.sided", paired=F, var.equal= T, mu= 0, conf.level=0.99)
classmateTimes <- data.frame(time = c(95.2, 103.5, 105.2, 105.2, 103.4, 102.8, 101.8, 97.9, 107.9	, 105.9, 110.5, 100.2))
# number of instances of data
n <- length(classmateTimes$time)
# Confidence and significance values (at 95% and 99%)
confidence1 <- 0.95
confidence2 <- 0.99
significance1 <- 1- confidence1
significance2 <- 1- confidence2
halfSignificance1 <- significance1/2
a <- 1 - halfSignificance1
halfSignificance2 <- significance2/2
b <- 1 - halfSignificance2
# degrees of freedom
dfTimes <- n - 1
# finding t-values
t1 <- qt(a, dfTimes)
t2 <- qt(b, dfTimes)
#standard deviation
sdTimes <- sd(classmateTimes$time)
# margin of error at 95% confidence
error1 <- t1*sdTimes/sqrt(n)
# margin of error at 99% confidence
error2 <- t2*sdTimes/sqrt(n)
# mean value
meanTimes <- mean(classmateTimes$time)
# Lower and upper limits at 95% confidence
lowerlimit1 <- meanTimes - error1
upperlimit1 <- meanTimes + error1
# Lower and upper limits at 99% confidence
lowerlimit2 <- meanTimes - error2
upperlimit2 <- meanTimes + error2
# confidence intervals
CI95 <- paste("Confidence interval at 95% confidence is (", lowerlimit1, ", ",  upperlimit1, ")")
CI99 <- paste("Confidence interval at 99% confidence is (", lowerlimit2, ", ",  upperlimit2, ")")
# Outputting the confidence intervals
CI95
CI99
p <- ggplot(classmateTimes, aes(x= time))
p <- p+ geom_dotplot( binwidth=1 )
p <- p + labs( x="",y="")
#p <- p + xlim(370,460)
p
p <- ggplot(classmateTimes, aes(sample = time))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
shapiro.test(classmateTimes$time)
t.test(classmateTimes$time, alternative = "two.sided", paired=F, mu= 100, conf.level=0.95)
t.test(classmateTimes$time, alternative = "two.sided", paired=F, mu= 100, conf.level=0.99)
fellowTimes <- data.frame(time=c(117.0, 116.3,117.9, 120.0, 125.5, 144.8, 120.6, 120.4, 137.6, 121.7, 123.2, 133.8))
# number of instances of data
n <- length(fellowTimes$time)
# Confidence and significance values (at 95% and 99%)
confidence1 <- 0.95
confidence2 <- 0.99
significance1 <- 1- confidence1
significance2 <- 1- confidence2
halfSignificance1 <- significance1/2
a <- 1 - halfSignificance1
halfSignificance2 <- significance2/2
b <- 1 - halfSignificance2
# degrees of freedom
dfTimes <- n - 1
# finding t-values
t1 <- qt(a, dfTimes)
t2 <- qt(b, dfTimes)
#standard deviation
sdTimes <- sd(fellowTimes$time)
# margin of error at 95% confidence
error1 <- t1*sdTimes/sqrt(n)
# margin of error at 99% confidence
error2 <- t2*sdTimes/sqrt(n)
# mean value
meanTimes <- mean(fellowTimes$time)
# Lower and upper limits at 95% confidence
lowerlimit1 <- meanTimes - error1
upperlimit1 <- meanTimes + error1
# Lower and upper limits at 99% confidence
lowerlimit2 <- meanTimes - error2
upperlimit2 <- meanTimes + error2
# confidence interval
CI95 <- paste("Confidence interval at 95% confidence is (", lowerlimit1, ", ",  upperlimit1, ")")
CI99 <- paste("Confidence interval at 99% confidence is (", lowerlimit2, ", ",  upperlimit2, ")")
# outputting values
CI95
CI99
p <- ggplot(fellowTimes, aes(x= time))
p <- p+ geom_dotplot( binwidth=1 )
p <- p + labs( x="",y="")
p
p <- ggplot(fellowTimes, aes(sample = time))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
shapiro.test(fellowTimes$time)
Week <- c(1:8)
Aberdeen <- c(7820, 6400, 8150, 7360, 7210, 8460, 6770, 7900)
Dundee <- c(6770, 6740, 7290, 7020, 7280, 7950, 6490, 7330)
profits <- data.frame(Week, Aberdeen, Dundee)
p <- ggplot(profits, aes(x= Aberdeen))
p <- p+ geom_dotplot( binwidth=50)
p <- p + labs( x="",y="")
p
p <- ggplot(profits, aes(x= Dundee))
p <- p+ geom_dotplot( binwidth=50)
p <- p + labs( x="",y="")
p
p <- ggplot(profits, aes(sample = Aberdeen))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
p <- ggplot(profits, aes(sample = Dundee))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
shapiro.test(profits$Aberdeen)
shapiro.test(profits$Dundee)
t.test(x=profits$Aberdeen, y=profits$Dundee , alternative = "two.sided", paired=T, mu= 0, conf.level=0.95)
profits$difference <- profits$Aberdeen - profits$Dundee
shapiro.test(profits$difference)
Recall.A <- c(71.5, 54.5, 70.2, 65.0, 83.9, 47.9, 49.1, 63.4, 64.2, 57.3, 61.7, 69.6, 75.8)
Recall.B <- c(59.9, 94.4, 67.0, 73.8, 83.3, 76.9, 70.4, 90.7, 75.8, 84.4, 74.7, 74.2, 64.5)
recallIndexing <-data.frame(Recall.A, Recall.B)
shapiro.test(recallIndexing$Recall.A)
shapiro.test(recallIndexing$Recall.B)
t.test(x=recallIndexing$Recall.A, y=recallIndexing$Recall.B , alternative = "two.sided", paired=F, var.equal= T, mu= 0, conf.level=0.99)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
algorithm <- read.csv("algorithm.csv", header=T, stringsAsFactors = T)
p <- ggplot(algorithm, aes(x= Algorithm.A)) +
geom_dotplot(binwidth=0.5, col="red", fill="red")
p <- p+ theme_classic() + labs (x="Algorithm A")
p <- p + theme(text = element_text(size = 20))
p
p <- ggplot(algorithm, aes(x= Algorithm.B)) +
geom_dotplot(binwidth=0.5, col="red", fill="red")
p <- p+ theme_classic() + labs (x="Algorithm B")
p <- p + theme(text = element_text(size = 20))
p
p <- ggplot(algorithm, aes(x= Algorithm.C)) +
geom_dotplot(binwidth=0.5, col="red", fill="red")
p <- p+ theme_classic() + labs (x="Algorithm C")
p <- p + theme(text = element_text(size = 20))
p
p <- ggplot(algorithm, aes(x= Algorithm.D)) +
geom_dotplot(binwidth=0.5, col="red", fill="red")
p <- p+ theme_classic() + labs (x="Algorithm D")
p <- p + theme(text = element_text(size = 20))
p
# creating mini data frames, one for each algorithm,
# each one containscone column with the name of the algorithm and one column with the time
algoA <- data.frame(time = algorithm$Algorithm.A, algorithm= "A")
algoB <- data.frame(time = algorithm$Algorithm.B, algorithm= "B")
algoC <- data.frame(time = algorithm$Algorithm.C, algorithm= "C")
algoD <- data.frame(time = algorithm$Algorithm.D, algorithm= "D")
# putting the 4 mini data frames together
dataAlgo <- rbind(algoA, algoB, algoC,algoD)
anova <- aov( time ~ algorithm, data = dataAlgo)
summary(anova)
# first construct a data frame with the rediduals. Then use it in the plot
anovaFrame <- data.frame(residuals = anova$residuals )
p <- ggplot(anovaFrame, aes(sample = residuals))
p <- p + stat_qq(size=2) + stat_qq_line( alpha = 0.7, color = "red", linetype = "dashed")
p <- p +  theme_classic()
p <- p + theme(text = element_text(size = 20))
p
shapiro.test(anova$residuals)
a <- power.t.test(power=0.8,delta=8,sd=10,sig.level=0.05,type="two.sample")
a
methods <- read.csv("methods.csv", header=T,stringsAsFactors=T)
# creating mini data frames, one for each algorithm,
# each one contains cone column with the number of documents and another with the method.
methodA <- data.frame(docNumber = methods$Method.A, method= "A")
methodB <- data.frame(docNumber = methods$Method.B, method= "B")
methodC <- data.frame(docNumber = methods$Method.C, method= "C")
# putting the 4 mini data frames together
dataMethod <- rbind(methodA, methodB, methodC)
anova <- aov( docNumber ~ method, data = dataMethod)
summary(anova)
anovaFrame <- data.frame(residuals = anova$residuals )
p <- ggplot(anovaFrame, aes(sample = residuals))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
shapiro.test(anovaFrame$residuals)
tool <- read.csv("tool.csv", header=T,stringsAsFactors=T)
# creating mini data frames, one for each algorithm,
# each one contains cone column with the number of documents and another with the method.
toolA <- data.frame(percentage = tool$Tool.A, tool = "A")
toolB <- data.frame(percentage = tool$Tool.B, tool= "B")
toolC <- data.frame(percentage = tool$Tool.C, tool= "C")
toolD <- data.frame(percentage = tool$Tool.D, tool= "D")
# putting the 4 mini data frames together
dataTool <- rbind(toolA, toolB, toolC, toolD)
anova <- aov( percentage ~ tool, data = dataTool)
summary(anova)
anovaFrame <- data.frame(residuals = anova$residuals )
p <- ggplot(anovaFrame, aes(sample = residuals))
p <- p + stat_qq()
p <- p + stat_qq_line( )
p
shapiro.test(anovaFrame$residuals)
a <- power.t.test(power=0.8,delta=8,sd=10,sig.level=0.05,type="two.sample")
b<- power.t.test(power=0.85,delta=8,sd=10,sig.level=0.05,type="two.sample")
c <- power.t.test(power=0.9,delta=8,sd=10,sig.level=0.05,type="two.sample")
d <- power.t.test(power=0.95,delta=8,sd=10,sig.level=0.05,type="two.sample")
e <- power.t.test(power=0.99,delta=8,sd=10,sig.level=0.05,type="two.sample")
f <- power.t.test(power=0.999,delta=8,sd=10,sig.level=0.05,type="two.sample")
## Displaying the results
cat(   "",
"n = ", ceiling(a$n), "units = ", a$delta, "power = ",  a$power, "significance level = ",  a$sig.level, "\n",
"n = ", ceiling(b$n), "units = ", b$delta, "power = ",  b$power, "significance level = ",  b$sig.level, "\n",
"n = ", ceiling(c$n), "units = ", c$delta, "power = ",  c$power,  "significance level = ",  c$sig.level,  "\n",
"n = ", ceiling(d$n), "units = ", d$delta, "power = ",  d$power, "significance level = ",  d$sig.level,  "\n",
"n = ", ceiling(e$n), "units = ", e$delta, "power = ",  e$power, "significance level = ",  e$sig.level,  "\n",
"n = ", ceiling(f$n), "units = ", f$delta, "power = ", f$power,  "significance level = ",  f$sig.level, sep = "\t")
powerVal <- c(a$power,b$power, c$power, d$power, e$power, f$power)
sampleSize <- c(a$n, b$n, c$n, d$n, e$n, f$n)
data <- data.frame(power = powerVal, sampleSeize = sampleSize)
p <- ggplot(data, aes(x=power, y=sampleSize))
p <- p+ geom_point(colour="red", size=3) + theme_classic() +labs(x= "Power", y= "Sample size (n)")
p <- p  + theme(text = element_text(size = 20))
p
power.t.test(power=0.7,delta=10,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.8,delta=10,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.9,delta=10,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.95,delta=10,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.7,delta=15,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.8,delta=15,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.9,delta=15,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.95,delta=15,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.7,delta=20,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.8,delta=20,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.9,delta=20,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.95,delta=20,sd=25,sig.level=0.05,type="two.sample", alternative ="two.sided")
power.t.test(power=0.7,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.8,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.9,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.95,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.7,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.8,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.9,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.95,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.7,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.8,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.9,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.95,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="two.sided")
power.t.test(power=0.7,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.8,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.9,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.95,delta=10,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.7,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.8,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.9,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.95,delta=15,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.7,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.8,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.9,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
power.t.test(power=0.95,delta=20,sd=25,sig.level=0.01,type="two.sample", alternative ="one.sided")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(tidyverse)
library(treemapify)
library(igraph)
library(ggraph)
library(ggwordcloud)
arrivals <- read.csv("arrivals.csv", header=T, stringsAsFactors=T)
numbersPerDay <- read.csv("numbersPerDay.csv", header=T, stringsAsFactors=T)
vessel <- read.csv("vessel.csv", header=T, stringsAsFactors=T)
summary(vessel$Draft)
IQR(vessel$Draft)
sd(vessel$Draft)
summary(arrivals$Draft)
IQR(arrivals$Draft)
sd(arrivals$Draft)
summary(vessel$Draft)
summary(arrivals$Draft)
summary(vessel$Draft)
IQR(vessel$Draft)
sd(vessel$Draft)
summary(arrivals$Draft)
IQR(arrivals$Draft)
sd(arrivals$Draft)
p <- ggplot(vessel, aes(Draft))
p <- p+geom_histogram(colour="tomato", fill="tomato", bins=40 ,aes(y=after_stat(density)) )
p <-  p+geom_density()
p <- p+labs( title="Vessel draft distribution", x = "Ship draft (metres)", y = "Count")
p
p <- ggplot(arrivals, aes(Draft))
p <- p+geom_histogram(colour="skyblue1", fill="skyblue1", bins=40,  aes(y=after_stat(density)))
p <-  p+geom_density()
p <- p+labs( title="Vessel draft distribution for arrivals", x = "Ship draft (metres)", y = "Count")
p
summary(vessel$Flag)
summary(arrivals$Flag)
p <- ggplot(vessel, aes(Flag))
p <- p+geom_bar(colour="coral3", fill="coral3")
p <- p+labs( title="Vessel flag distribution", x = "Ship flag", y = "Count")
p
p <- ggplot(arrivals, aes(Flag))
p <- p+geom_bar(colour="forestgreen", fill="forestgreen")
p <- p+labs( title="Arrivals flag distribution", x = "Ship flag", y = "Count")
p
p <- ggplot(numbersPerDay, aes(x=Day, y=ArrivalNumber, colour=DayName))
p <- p+geom_point()
p <- p+geom_line()
p <- p+labs( title="Arrivals per day", x = "Day", y = "Number of arrivals", colour="Day of the week")
p
p <- ggplot(vessel, aes(Draft, colour = Type))
p <- p+geom_point(aes(y = Beam))
p <- p+labs( title="Ship draft vs ship beam", x = "Ship draft (metres)", y = "Ship beam (metres)")
p
set.seed(3)
companies <- as.data.frame(table(arrivals$ShippingCompany))
# Give the columns proper names
names(companies) <- c("Company","count")
p <- ggplot(companies, aes(label = Company, size=count))
p <- p +  geom_text_wordcloud_area(colour="blue")
p <- p +   scale_size_area(max_size = 40)
p <- p +   labs(title= "Most common shipping companies for vessels arriving at  Barcelona")
p
vessel2 <- vessel |> filter(FlagCountry == "Turkey")
link_top_2 <- vessel2 |>
select(FlagCountry, Name) |>
unique() |>
rename(from=FlagCountry, to=Name)
link_2_3 <- vessel2 |>
select(Name, Length) |>
unique() |>
rename(from=Name, to=Length)
link_2_3$to <- as.factor(link_2_3$to)
# Getting all the links into one data frame
links <- rbind(link_top_2, link_2_3)
dendro2 <- graph_from_data_frame(links)
p <- ggraph(dendro2, layout = 'dendrogram',
circular = FALSE)
p <- p + geom_node_label(aes(label = name),  size=3,
repel = TRUE, colour="darkgreen",fill="lightyellow",show.legend = TRUE)
p <- p + geom_edge_diagonal(colour="darkgreen")
p <- p + geom_node_point(colour="darkgreen")
p <- p + labs(title="Length of vessels from Malta (in metres)")
p
cor(vessel$Beam,vessel$Length)
p <- ggplot(vessel, aes(x=Length, y = Beam))
p <- p+geom_point()
p <- p+ geom_smooth(method="lm", formula= "y~x")
p <- p+labs( title="Ship length vs ship beam", x = "Ship length (metres)", y = "Ship beam (metres)")
p
lm.output <- lm(formula = vessel$Beam ~ vessel$Length)
summary(lm.output)
r <-  lm.output$residuals
re <- data.frame(res=r)
p <- ggplot(re, aes(res))
#p <- p+geom_histogram(colour="wheat", fill="wheat", bins=40 , aes(y=..density..))
p <-  p+geom_density()
p <- p+labs( title="Residual distribution", x = "Residual", y = "Frequency")
p
r <-  lm.output$residuals
re <- data.frame(r)
p <- ggplot(re, aes(res))
#p <- p+geom_histogram(colour="wheat", fill="wheat", bins=40 , aes(y=..density..))
p <-  p+geom_density()
p <- p+labs( title="Residual distribution", x = "Residual", y = "Frequency")
p
r <-  lm.output$residuals
re <- data.frame(res=r)
re
r <-  lm.output$residuals
re <- data.frame(r)
re
r <-  lm.output$residuals
re <- data.frame(res=r)
re
r <-  lm.output$residuals
re <- data.frame(res=r)
res
r <-  lm.output$residuals
re <- data.frame(res=r)
p <- ggplot(re, aes(res))
#p <- p+geom_histogram(colour="wheat", fill="wheat", bins=40 , aes(y=..density..))
p <-  p+geom_density()
p <- p+labs( title="Residual distribution", x = "Residual", y = "Frequency")
p
lmData <-
data.frame(residuals = lm.output$residuals,
Length= vessel$Length,
Beam = vessel$Beam)
p <- ggplot(lmData, aes(sample = residuals))
p <- p + stat_qq(size=2) +
stat_qq_line( alpha = 0.9, color = "red",
linetype = "dashed")
p <- p +  theme_classic()
p <- p + theme(text = element_text(size = 20))
p
shapiro.test(lmData$residuals)
lm.output2 <- lm(Beam ~Length+Draft, data = vessel)
summary(lm.output2)
